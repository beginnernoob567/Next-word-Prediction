{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a9e001a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Libraries\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Load the model and tokenizer\n",
    "\n",
    "model = load_model('nextword1.h5')\n",
    "tokenizer = pickle.load(open('tokenizer1.pkl', 'rb'))\n",
    "\n",
    "def Predict_Next_Words(model, tokenizer, text):\n",
    "    \"\"\"\n",
    "        In this function we are using the tokenizer and models trained\n",
    "        and we are creating the sequence of the text entered and then\n",
    "        using our model to predict and return the the predicted word.\n",
    "    \n",
    "    \"\"\"\n",
    "    for i in range(3):\n",
    "        sequence = tokenizer.texts_to_sequences([text])[0]\n",
    "        sequence = np.array(sequence)\n",
    "        \n",
    "        preds = model.predict(sequence)\n",
    "#         print(preds)\n",
    "    predicted=''\n",
    "    for key,value in tokenizer.word_index.items():\n",
    "        if value==np.argmax(preds,axis=1):\n",
    "            predicted=key\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2d0c4737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "weather\n"
     ]
    }
   ],
   "source": [
    "text='at the dull'\n",
    "text=text.split(\" \")\n",
    "text=text[-1]\n",
    "text=''.join(text)\n",
    "print(Predict_Next_Words(model,tokenizer,text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0a898c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your line: at the dull\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "weather\n",
      "Enter your line: what a strenuous\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "career\n",
      "Enter your line: when gregor samsa\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "and\n",
      "Enter your line: hi i am\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "astonished\n",
      "Enter your line: you are a\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "little\n",
      "Enter your line: hi i love \n",
      "Enter your line: i love\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "to\n",
      "Enter your line: i love you\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "can\n",
      "Enter your line: you are my\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "parents\n",
      "Enter your line: what is your\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "parents\n",
      "Enter your line: i am a \n",
      "Enter your line: i am very\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "carefully\n",
      "Enter your line: stop the script\n",
      "Ending The Program.....\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "\n",
    "    text = input(\"Enter your line: \")\n",
    "    \n",
    "    if text == \"stop the script\":\n",
    "        print(\"Ending The Program.....\")\n",
    "        break\n",
    "    \n",
    "    else:\n",
    "        try:\n",
    "            text = text.split(\" \")\n",
    "            text = text[-1]\n",
    "\n",
    "            text = ''.join(text)\n",
    "            print(Predict_Next_Words(model,tokenizer,text))\n",
    "\n",
    "            \n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3da653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6400419",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
